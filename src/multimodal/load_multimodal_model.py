"""
å¤šæ¨¡æ€æ¨¡å‹åŠ è½½å™¨
æ”¯æŒæ ¹æ®curlå‘½ä»¤å°è£…è¯·æ±‚æ–¹æ³•ï¼Œå¹¶å¤„ç†å›¾ç‰‡è·¯å¾„è½¬base64ç¼–ç 
"""

import base64
import json
import os
from typing import Dict, List

import requests

from src.get_start import get_start_dir


class MultimodalModelLoader:
    """å¤šæ¨¡æ€æ¨¡å‹åŠ è½½å™¨ç±»"""
    
    def __init__(self, base_url: str = "http://localhost:1234/v1"):
        """
        åˆå§‹åŒ–å¤šæ¨¡æ€æ¨¡å‹åŠ è½½å™¨
        
        Args:
            base_url (str): APIåŸºç¡€URLï¼Œé»˜è®¤ä¸ºæœ¬åœ°LM StudioæœåŠ¡
        """
        self.base_url = base_url.rstrip('/')
        self.chat_endpoint = f"{self.base_url}/chat/completions"
    
    def image_to_base64(self, image_path: str) -> str:
        """
        å°†å›¾ç‰‡æ–‡ä»¶è½¬æ¢ä¸ºbase64ç¼–ç 
        
        Args:
            image_path (str): å›¾ç‰‡æ–‡ä»¶è·¯å¾„
            
        Returns:
            str: base64ç¼–ç çš„å›¾ç‰‡æ•°æ®
            
        Raises:
            FileNotFoundError: å½“å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨æ—¶
            Exception: å…¶ä»–è¯»å–é”™è¯¯
        """
        try:
            if not os.path.exists(image_path):
                raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            
            with open(image_path, "rb") as image_file:
                image_data = image_file.read()
                base64_data = base64.b64encode(image_data).decode('utf-8')
                return base64_data
                
        except Exception as e:
            raise Exception(f"è½¬æ¢å›¾ç‰‡ä¸ºbase64æ—¶å‡ºé”™: {e}")
    
    def create_image_message(self, image_path: str, text: str = "") -> Dict:
        """
        åˆ›å»ºåŒ…å«å›¾ç‰‡çš„æ¶ˆæ¯æ ¼å¼
        
        Args:
            image_path (str): å›¾ç‰‡æ–‡ä»¶è·¯å¾„
            text (str): å¯é€‰çš„æ–‡æœ¬å†…å®¹
            
        Returns:
            Dict: åŒ…å«å›¾ç‰‡çš„æ¶ˆæ¯å­—å…¸
        """
        base64_image = self.image_to_base64(image_path)
        
        message = {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": text
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}"
                    }
                }
            ]
        }
        
        return message
    
    def chat_completion(
        self,
        messages: List[Dict],
        model: str = "google/gemma-3n-e4b",
        temperature: float = 0.7,
        max_tokens: int = -1,
        stream: bool = False
    ) -> Dict:
        """
        å‘é€èŠå¤©å®Œæˆè¯·æ±‚
        
        Args:
            messages (List[Dict]): æ¶ˆæ¯åˆ—è¡¨
            model (str): æ¨¡å‹åç§°
            temperature (float): æ¸©åº¦å‚æ•°
            max_tokens (int): æœ€å¤§tokenæ•°ï¼Œ-1è¡¨ç¤ºæ— é™åˆ¶
            stream (bool): æ˜¯å¦æµå¼å“åº”
            
        Returns:
            Dict: APIå“åº”ç»“æœ
        """
        payload = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "stream": stream
        }
        
        headers = {
            "Content-Type": "application/json"
        }
        
        try:
            response = requests.post(
                self.chat_endpoint,
                headers=headers,
                json=payload,
                timeout=60
            )
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            raise Exception(f"APIè¯·æ±‚å¤±è´¥: {e}")
    
    def chat_with_image(
        self,
        image_path: str,
        text: str = "",
        system_prompt: str = "You are a helpful assistant.",
        model: str = "google/gemma-3n-e4b",
        temperature: float = 0.7,
        max_tokens: int = -1,
        stream: bool = False
    ) -> Dict:
        """
        å‘é€åŒ…å«å›¾ç‰‡çš„èŠå¤©è¯·æ±‚
        
        Args:
            image_path (str): å›¾ç‰‡æ–‡ä»¶è·¯å¾„
            text (str): ç”¨æˆ·æ–‡æœ¬æ¶ˆæ¯
            system_prompt (str): ç³»ç»Ÿæç¤º
            model (str): æ¨¡å‹åç§°
            temperature (float): æ¸©åº¦å‚æ•°
            max_tokens (int): æœ€å¤§tokenæ•°
            stream (bool): æ˜¯å¦æµå¼å“åº”
            
        Returns:
            Dict: APIå“åº”ç»“æœ
        """
        # åˆ›å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = []
        
        # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
        if system_prompt:
            messages.append({
                "role": "system",
                "content": system_prompt
            })
        
        # æ·»åŠ åŒ…å«å›¾ç‰‡çš„ç”¨æˆ·æ¶ˆæ¯
        image_message = self.create_image_message(image_path, text)
        messages.append(image_message)
        
        # å‘é€è¯·æ±‚
        return self.chat_completion(
            messages=messages,
            model=model,
            temperature=temperature,
            max_tokens=max_tokens,
            stream=stream
        )
    
    def simple_chat(
        self,
        user_message: str,
        system_prompt: str = "You are a helpful assistant.",
        model: str = "google/gemma-3n-e4b",
        temperature: float = 0.7,
        max_tokens: int = -1,
        stream: bool = False
    ) -> Dict:
        """
        ç®€å•çš„æ–‡æœ¬èŠå¤©è¯·æ±‚
        
        Args:
            user_message (str): ç”¨æˆ·æ¶ˆæ¯
            system_prompt (str): ç³»ç»Ÿæç¤º
            model (str): æ¨¡å‹åç§°
            temperature (float): æ¸©åº¦å‚æ•°
            max_tokens (int): æœ€å¤§tokenæ•°
            stream (bool): æ˜¯å¦æµå¼å“åº”
            
        Returns:
            Dict: APIå“åº”ç»“æœ
        """
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message}
        ]
        
        return self.chat_completion(
            messages=messages,
            model=model,
            temperature=temperature,
            max_tokens=max_tokens,
            stream=stream
        )


def demo_basic_chat():
    """æ¼”ç¤ºåŸºç¡€èŠå¤©åŠŸèƒ½"""
    print("ğŸš€ æ¼”ç¤ºåŸºç¡€èŠå¤©åŠŸèƒ½")
    print("=" * 50)
    
    loader = MultimodalModelLoader()
    
    try:
        # ä½¿ç”¨åŸå§‹curlå‘½ä»¤çš„å‚æ•°
        result = loader.simple_chat(
            user_message="What day is it today?",
            system_prompt="Always answer in rhymes. Today is Thursday",
            model="google/gemma-3n-e4b",
            temperature=0.7,
            max_tokens=-1,
            stream=False
        )
        
        print("ğŸ“Š APIå“åº”:")
        print(json.dumps(result, indent=2, ensure_ascii=False))
        
        # æå–å›å¤å†…å®¹
        if "choices" in result and len(result["choices"]) > 0:
            content = result["choices"][0]["message"]["content"]
            print(f"\nğŸ’¬ æ¨¡å‹å›å¤: {content}")
        
        return result
        
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        return None


def demo_image_chat(image_path: str):
    """æ¼”ç¤ºå›¾ç‰‡èŠå¤©åŠŸèƒ½"""
    print(f"\nğŸš€ æ¼”ç¤ºå›¾ç‰‡èŠå¤©åŠŸèƒ½")
    print("=" * 50)
    print(f"ğŸ“· å›¾ç‰‡è·¯å¾„: {image_path}")
    
    loader = MultimodalModelLoader()
    
    try:
        result = loader.chat_with_image(
            image_path=image_path,
            text="è¯·æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹",
            system_prompt="You are a helpful assistant that can analyze images.",
            model="google/gemma-3n-e4b",
            temperature=0.7,
            max_tokens=-1,
            stream=False
        )
        
        print("ğŸ“Š APIå“åº”:")
        print(json.dumps(result, indent=2, ensure_ascii=False))
        print("="* 50)
        # æå–å›å¤å†…å®¹
        if "choices" in result and len(result["choices"]) > 0:
            content = result["choices"][0]["message"]["content"]
            print(f"\nğŸ’¬ æ¨¡å‹å›å¤: {content}")
        
        return result
        
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        return None


if __name__ == "__main__":
    # æ¼”ç¤ºåŸºç¡€èŠå¤©åŠŸèƒ½
    # demo_basic_chat()
    
    # æ¼”ç¤ºå›¾ç‰‡èŠå¤©åŠŸèƒ½ï¼ˆéœ€è¦æä¾›å›¾ç‰‡è·¯å¾„ï¼‰
    demo_image_chat(get_start_dir + "/graph_img/human_graph.png")
